<목차> 

1. 빅데이터 수집 및 전송 
2. 빅데이터 스트리밍 및 Kinesis 
3. 빅데이터 스토리지 솔루션 
4. 빅데이터 처리 및 분석 (Athena) 
5. Hadoop 및 EMR 
6. EMR 사용 
7. EMR에서 Hive로 서버 로그 처리하기 
8. EMR 의 Hue에서 Pig 스크립트 실행하기 
9. EMR 기반 Spark 
10. Glue를 사용한 ETL 자동화 
11. Redshift 및 빅데이터 
12. 배포 보안 
13. 빅데이터 비용 관리 
14. 빅데이터 시각화 및 조정 
15. 빅데이터 설계 패턴 
---------------------------------------------------------------
<분류> 
수집 
	- 준실시간 > Kinsis Firehose 
	- 데이터 적재 > Snowball 
	- 메세지 대기열 > SQS 
	- 웹/앱서버 > EC2 
	
저장 
	- 객체 스토리지 : S3, Glacier 
	- 준실시간 : Kinesis Stremas 
	- RDBMS : RDS 
	- NoSQL : DynomoDB 
	- 검색 : CloudSearch 
	- 사물인터넷 : IoT 

처리 및 분석 
	- 하둡에코 : EMR 
	- 준실시간 : Lambda, Kinesis Analytics 
	- DW : Redshift 
	- ML기계학습 : SageMaker 
	- 탄력적 검색 분석 : Elasticsearch Service 
	- 데이터 처리 및 이전 : Data Pipeline , Glue 
	- 임시분석 Athena 
	
시각화 
	- BI 및 시각화 : QuickSight 
	- 탄력적 검색 분석 : Elasticsearch Service 

---------------------------------------------------------------
<0. 빅데이터 아키텍처 원칙>
1) 결합 해제 
	- 저장 -> 처리 -> 저장 -> 처리 ... (결합을 해제)
	- 내결함성이 향상된다. 중간 작업이 실패하는 경우 중간 단계부터 수행할 수 있다. 
	- 복수의 처리 어플리케이션이 복수의 데이터 스토어에서 데이터를 읽고 슬 수 있다. (병렬 처리 가능) 
	- 중간 단계의 데이터를 사용자가 볼 수 있음으로 쉽게 통찰을 얻을 수 있다. 
	
2) 올바른 도구 사용 
	- 데이터 구조 : 처리 방법과 저장소 모두에 영향
	- 최대 허용 지연 시간 
	- 최소 허용 처리량 : 처리량과 지연시간은 일반적으로 상반된 속성으로 어디에 가중치를 둘 것이냐가 중요
	- 시스템 최종 사용자의 일반적인 액세스 패턴 : 배치? 실시간? / 전체 데이터? 일부 데이터? 
	
3) 가능한 경우 관리형 서비스 활용 
	- Kinesis, Redshift, RDS, DynamoDB, Lambda, Elasticsearch Service, Cloudsearch, SQS, Data Pipeline, Beanstalk, SageMaker
	
---------------------------------------------------------------
<1. 빅데이터 수집 및 전송>
1) 수집 유형 
	- 트랜잭션 (DB read/write) 
		. 웹/앱서버 에서 발생하는 작은 크기의 데이터를 신속하게 저장하고 검색할 수 있어야 한다.  
		. DynamoDB, RDS 
	- 파일 
		. 디바이스 등에서 생성되는 개별파일 데이터는 빠른 저장 및 검색이 필요하지 않고, 전송이 일방향 이고, 다양한 소스로부터 수집이 이루어진다. 
		. Flume, Log4j 등을 통해서 S3에 적재 
	- 스트림
		. 클릭스트림 로그와 같은 스트림 데이터는 Fluentd, Sqoop, Storm, Kinesis producer, Kinesis Firehose를 통해 수집 
		. Kinesis Streams와 같은 스트림 스토리지 솔루션에 저장 수 실시간 처리 및 분석 
		. 장기간으로는 S3에 저장해야 됨 

2) 수집 도구 
	. Kinesis Agent 
		> Kinesis Data Streams, Kinesis Data Firehose에 직접 쓸 수 있다. 
		> Linux 기반 서버 환경에 설치하여 수집 파일을 지속적으로 모니터링 하고 전처리하여 신규 데이터를 Kinesis Streams/Firehose에 전송한다. 
		> CloudWatch에 지표를 생성하여 스트리밍 프로세스 모니터링 및 지표를 알려준다. 
		> SINGLELINE, CSVTOJSON, LOGTOJSON 기능 제공 및 오픈소스 임으로 추가 개발 확장 가능하다. 
	
	. Apache Flume 
		> EC2 인스턴스 등에 설치하여 HDFS 또는 S3에 대용량 로그데이터를 효율적으로 수집/집계할 수 있다. 
		
	. S3DistCP 
		> S3와 HDFS간 대용량 데이터 복사를 가능하게 함 , 또는 S3 버킷 간 데이터 복사 
		> HDFS to S3 일 경우) HDFS 출력 임시본 생성 -> S3에 최종 복사본 업로드 -> HDFS 에서 임시본 제거.  단, 중간에 에러나는 경우 임시본 수동 삭제 필요 
		> S3DistCP 하는 경우 비압축 데이터를 압축하여 전송시킬 수 있다. 
		> 파일이 존재하면 덮어 씀. S3 버킷 이름에 언더바 있는 경우 복사 안됨 
	
	. Sqoop 
		> RDB, HDFS 양방향 전송. 맵 전용 작업 생성. (EMR 사용하는 경우 사용함. DW에 데이터를 쓰고 시각화 도구를 통해 통찰 얻을 수 있음) 
		
	. VPC 구성 및 VPN 연결 
		> 해당 구성을 통해 사내 데이터 센터와 연결하여 AWS 빅데이터 서비스를 사용할 수 있음. 
		> 인터넷 -> VPN -> AWS Virtual GW -> AWS subnet  연결 
	
	. VPC 구성 및 DirectConnect(DX) 연결 
		> 고객 onprem에서 AWS로 전용 네트워크 연결 가능 
		> 전용 망을 사용하기 때문에, 네트워크 비용 줄이고 대역폭을 늘리 수 있으며 일관된 네트워크 환경 제공 
		> 퍼블릭/프라이빗 유지하면서 프라이빗 리소스에도 접근이 가능함 
		
	. S3 멀티파트 업로드 
		> S3는 단일 업로드 최대 5GB 크기 객체 업로드, 5MB ~5TB 까지 멀티 파트 업로드 가능, 100 MB 이상의 객체는 멀티파트 업로드 사용 권장. 
		> 멀티파트 업로드로 Direct Connect, VPN, 또는 인터넷 연결을 통해 파일 전송 가능 . 
	
	. Snowball 
		> 페타 바이트 규모의 데이터 전송 솔루션. 보안 어플라이언스를 사용해 대량 데이터 전송.
		> 클라우드 마이그레이션, 재해복구 -> AWS Snowball 
		> 사물인터넷, 원격 위치 -> AWS Snowball Edge  , 자체적으로 로컬 클러스터링 구성. 원격지에서 전송 (스토리지를 컴퓨팅 기능과 함께 로컬 환경에 구현). Lambda 함수 실행. 네트워크 연결 가능. 
		> 엑사 바이트 규모 데이터 센터 이전 -> Snowmobile (초당 1TB, 10PB 이상은 추천) 
		
	. AWS IoT
		> 디바이스가 클라우드 앱 및 다른 디바이스와 상호작용할 수 있도록 함 
		> 인프라 관리 필요 없이 수십억 개 디바이스와 수조 건의 메세지 지원. 데이터 수집 저장 및 분석 처리 
		> Lambda, Kinesis, S2, ML, DynamoDB 와 통합 가능 
		> 규칙엔진으로 데이터를 자동으로 필토링 하고 변환. (json 형태로 정의) 
		
---------------------------------------------------------------
<2. 빅데이터 스트리밍 처리 및 Kinesis>
1) 스트리밍 데이터 솔루션 사용 이유 
	- 수집과 처리의 분리 
	- 복수의 스트림 동시 처리 
	- 클라이언트 순서 유지 
	- 병렬 소비 

2) 스트림 처리 솔루션 특징 
	- 짧은 지연 시간 
	- 메세지 전송 보장 
	- lambda 아키텍처 구현 
	- 스트림 데이터의 상태 관리 
	- 시간 또는 횟수 기반 범위 지정 지원 
	- 내결함성 

3) Kinesis
	- Data Firehose (스트림 캡처 -> 변환 -> 적재) , 지연 60초
		. 완전 관리형 서비스로 스트리밍 데이터를 lambda 를 통해 변환하여 Data Analytics, S3, Redshift, ES 로 적재하여 준실시간 분석 처리 가능하게 함. 
		. 데이터를 로드 하기 전에 배치 처리, 압축 및 암호화 가능 (배치?) 
		. 스트림 생성(리스너) ->Kinesis Agent  또는 Firehose API(PutRecord, PutRecordBatch) 에서 스트림에 데이터 전달 -> 설정한 Lambda를 통해 변환 -> 타겟 적재 (S3, Redshift)
		. 처리된 데이터 양에 대해서 과금 
		. 전송스트림Delivery Stream - Firehose 기반 엔티티로 delivery stream 생성후 데이터를 delivery stream으로  전달
		. 레코드는 blob 단위로 데이터 생산자(kinesis agent / firehose API)에서 delivery stream 으로 전송. 최대 크기 1MB 
		. 타겟에 적재 전에 일정 단위로 버퍼링 후 전달한다. 버퍼링 크기 단위 MB, 시간 단위 초 
		. 파티션 키 없음, 프로비저닝 없음, 샤딩 없음 -(알아서 다 해줌?)
		
	- Data Streams , 생성자-스트림-소비자, 지연 10초 
		. 관리형 서비스로 실시간 스트리밍 데이터 수집, 처리, 및 분석 수행 
		. Data Streams 스트림 생성(샤드 설정) -> Kinesis 생산자가 스트림에 데이터 넣어줌 -> Kinesis 소비자가 
		. 여러 소비자가 동시에 하나의 스트림으로 부터 데이터를 읽을 수 있음. 다양한 타겟에 데이터 전달 가능 
		. 소비자=kinesis app 에서는 데이터 처리, 분석, 학습이 수행될 수 있으며 처리 후 타겟에 적재 가능하다. 
		. 샤드 당 초당 5건/2MB의 읽기 지원. 초당 1000건 쓰기/1MB의 쓰기 지원. 
		. 소비자(kinesis app)은 EC2인스턴스에 올릴 수 있고 ASG를 통해 확장할 수 있다. 
	
	- Kinesis Client Library (KCL) : Kinesis Data Stream을 처리하기 위한 라이브러리. 샤드를 간단하게 해줘 읽고 처리하기 편하게 해준다. 샤드 수에 따라 worker 를 늘리고 줄인다. check pint 추적, 내결함성 
	- Kinesis Connector Library : kinesis 를 다양한 타겟에 붙여준다. 
	
	- Kinesis Firehose와 Kinesis Streams 비교 
		. KF(완전 관리형-관리 필요 없음) vs KS(유입 레코드에 대한 사용자 지정 처리 필요) 
		. KF(처리 지연 시간 60초) vs KS(처리 지연시간 1초) 
		. KF(S3, Redshift, ES 등 기존 분석 도구 사용) vs KS(스트림 처리 프레임워크 선택?-소비자 app 개발, storm/spark) 
	
	- Data Analytics 
		. 완전 관리형 서비스 
		. 원본 데이터 Kinesis Streams / Kinesis Firehose 의 스트림 
		. KS, KF의 스트림 연결 후 Kinesis Data analytics 로 SQL수행 
		. 자동으로 스키마 추론함 
		. 1초 미만의 처리 지연 시간 
		. S3를 참조 데이터 원본으로 app 시작시 참조 테이블 생성 
		. 처리된 데이터를 S3, RS, ES, 또 다른 스트림 으로 전달(lambda를 통해 사용) 

	- Video Streams : 생산자/소비자 구조. VS가 내부적으로 처리/변환 수행 
	- Spark Streaming : 1초 미만의 마이크로 배치 (RDD의 시퀀스인 Dstreams사용) 
	- Kafka  : MS, Kafka stream 을 통해 데이터 처리 및 분석 수행 . 
	- on EC2  : Flume, Storm, Samza, Flink 
	
	- 처리 예시1) 
	> 클릭 스트림 로그는 별도 처리가 필요 없음으로 Firehose 스트림으로 수집 후 S3에 적재. 장기 데이터는 Glacier로 이동. 
	> 복잡한 처리가 필요한 스트림 데이터는 Kinesis streams 에 적재(생산자가 선택적으로 특정 스트림에 적재 할 수 있음), 후 적재된 스트림 따라서 소비자 app이 처리하여 결과를 S3에 저장 
	
	- 처리 예시2) 
	> 원본 데이터는 S3에 별도 적재 , 동시에 해당 스트림을 소비자 앱에 보낼 수 있음 (fork 같이) 
	> 처리 실패 건에 대해서도 별도 저장을 수행해야 함 
	
	- 추가 스트리밍 저장 옵션 
		. DynamoDB Streams 
		. SQS
		. SNS (pub/sub) 
		
	- !!! 어떤 스트림 스토리지를 사용해야 하는가? 
		. 관리형 우선 - Kinesis 같은 관리형 서비스는 관리 포인트가 줄어든다.  + 서버리스 
		. 순서 지정 - Stream 순서 지정은 순서대로 데이터를 소비할 수 있게 해준다. Kinesis (data streams) 는 샤드 수준에서만 순서를 보장한다!!!
		. Kinesis 는 최소 한번 전송만 보장함으로, 두번이상 데이터를 보내는 경우가 발생할 수 있다. 따라서 이후 중복 제거 작업을 통해 대처해야 한다. 
		. KS 는 데이터 유지기간 7일, KF는 별도 데이터 유지기간 없음 (바로 전달하기 때문에) 

	##### 스트림 프로세서 선택 기준 
		. 어느정도의 처리량? 
		. 확장 / 축소 기능을 가지고 있나? 
		. 내결함성을 가지고 있나? 
		. 전송 보장을 제공하나?
		. 어떤 프로그래밍 언어를 지원하나? 
		. 누가 관리할 것인가? (뭐가 관리형 서비스냐?) 
		
---------------------------------------------------------------
<3.빅데이터 스토리지 솔루션>

1) 개요 
- 하나의 단일 솔루션을 사용해서 모든 데이터 스토리지 요건을 처리하지 말것 -> 모든 작업에 최적화된 도구는 없다.
- 스토리지 종류 
	. ElasticCache - 캐쉬 
	. DynamoDB - NoSQL 
	. RDS - SQL(RDB) 
	. Neptune - Graph DB 
	. S3, Glacier - Blob Store(object storage) 
	. EMR - HDFS 
	. CloudSearch , ES - 검색 

-  DL vs DW 
	. 읽기용 스키마 vs 쓰기용 스키마 
	. 미정의 스키마 vs 사전 정의된 스키마 
	. 구조화,반구조화,비구조화 데이터 vs 구조화 데이터 
	. 도구 유연성 가짐 vs 호환되는 SQL만 제공 
	. 세분화 정도가 낮음 vs 요약/집계된 데이터 
	
- DataLake을 AWS S3를 사용하고, 올바른 데이터를 사용해 집계처리함 
	. 높은 내구성, 99.99가용성, 고성등(멀티파트 업로드), 사용 편의성(rest, sdk, 수명주기 등), 확장성, AWS 서비스들과 통합 

- Cold Data는 AWS Glacier 에 보관/백업 
	. 객체 스토리지, 매우 낮은 비용, 액세스가 빈번하지 않은 데이터, 쿼리 되지 않는 비구조화 데이터에 이상적임 
	
- NoSQL = DynamoDB 에 사용. 매우 다양한 NoSQL 기능이 있음 
	. 엄격칸 스키마를 따를 필요가 없음 
	. 최종 일관성을 보장함 - ACID 미준수
	. 분산되어 복제/이중화가 가능 - 수평적 확장 
	. 높은 가용성을 제공 - 스토리지 최적화는 아님 
	. 종류 
		> columnar DB : 열기반 데이터 구조에 적합. IO를 대폭 완화시켜줌 (HBase, Cassandra) 
		> document DB : 반구조화 데이터 문서(Json, xml)로 저장되는 형식을 효율적으로 직렬화 하여 로드할 수 있도록 해줌 (MongoDB, Cassandra, CouchBase, MarkLogic) 
		> Graph data DB : SQL/NoSQL 을 구축할 수 있음. 그래프를 효율적으로 순회할 수 있도록 해줌 
		> InMem key-value  : 읽기 중심의 워크로드 및 컴퓨팅 중심의 워크로드에 최적화된 NoSQL 
		
- DynamoDB 
	. 완전 관리형 NoSQL 
	. 문서 및 key-value 스토어
	. 고성능(ssd) , 10ms , 보조 인덱스 제공 
	. EMR과 결합하여 복잡한 Hive쿼리 수행, DynamoDB 테이블을 S3테이블과 조인 가능. 
	. 테이블은 파티션키, 정렬키(선택), 보조인덱스, 속성(key-value/doc) 으로 구성됨 / 글로벌 테이블은 다중리전, 다중 마스터DB 제공 
	. 인덱싱 
		> 기본 키 기준으로 인덱싱 되고 분할 : (파티션키와 정렬키)
		> 보조 인덱스로 로컬 보조 인덱스(LSI)와 글로벌 보조 인덱스(GSI)를 사용 
			. LSI local secondary index : 기반 테이블과 파티션키는 같지만 정렬키를 다르게 둠. 
			. GSI Global secondary index : 기반 테이블과 파티션키와 정렬키 모두가 다를 수 있음. 
			. 테이블 당 각각 5개까지 최대로 만들 수 있음. 
			. 파티션 단위로 데이터 저장(ssd), 리전내 복수의 가용영역으로 자동 복제, DynamoDB가 파티션 관리 알아서 해줌 
			
- DynamoDB Accelerator(DAX) 
	. 복잡한 앱을 위해 인메모리 성능을 제공하는 DynamoDB 호환 캐싱 서비스
	. 매우 낮은 응답시간을 제공해야 되는 경우 사용 
	. Dynamo API와 호환되는 관리형 서비스를 제공하여 앱 복잡성을 줄이고 기존 앱과 통합시킴 
	. 읽기중심의 순간 확장 워크로드가 발생하는 경우, 프로비저닝 필요성을 줄여줘서 운영비용을 줄여줌 
	
- Amazon Neptune 
	. 고도로 연결된 데이터 셋에서 작업한느 app을 구축하는 경우 
	. 완전 관리형 그래프 DB서비스, tinkerpop 및 sparql 표준을 지원 
	. 고가용성, 읽기 전용 복제본, 특정 시점 복구, S3로 지속적인 백업, AZ간 복제 
	
- JanusGraph 
	. 분산형 그래프로, 플러그인 아키텍처를 지닌 스토리지 계층 
	. Solr, ES를 검색엔진으로 사용하고 DynamoDB를 스토리지 백엔드로 사용할 수 있음 
	. 멀티 마스터 복제를 위한 HA(cassandra 백엔드) 

- 인메모리 key-value 스토어 
	. 지연 시간이 1ms 미만 
	. 빈번하게 액세스 되지만, 자주 업데이트 되지 않는 데이터 영역
	. 쿼리 시 IO 부담이 없고 높은 처리량과 고가용성을 제공 

- ElasticCach 
	. 완전 관리형 인메모리 key-value 스토어로 memcached / redis 를 엔진으로 지원 
	. 리더보드, 고속정렬, 대기열 지원, 활동 추적
	
- Redshift 
	. PB 규모 데이터 베이스 
	. 칼럼 기반 스토리지로 SQL 작업을 병렬/분산 처리 
	. 고성능 데이터 프로세싱 설계 / 로컬 연결 스토리지 사용 / 10G 네트워크 사용 

- RDS
	. mysql, mariaDB, postgreSQL, oracle, MSSQL, aurora 지원 
	. 다중 AZ 배포, 표준형 스토리지 및 프로비저닝된 IOPS 를 지원하여 빠른 성능 구현 
	. Sqoop을 써서 EMR 데이터를 RDS로 직접 출력 . (양방향) 
	
- EMR(HDFS) 
	. 스토리지 최적화 인스턴스로 디스크 공간 절약 
	. 데이터는 로컬이며 S3로 부터 스트리밍 되지 않음 
	. 필요한 경우 S3로 복사할 수 있음 
	. EC2인스턴스에 의해 제공되는 휘발성 인스턴스 스토어(EBS는 EMR 2.4 이상) 
	. EMRFS로 높은 성능으로 안전하게 S3에 읽고 쓰기 수행 (일관성의 보장) , 중간파일 EBS에 저장
	. EMR 인스턴스를 종료하면 EBS 볼륨도 같이 삭제 (확장의 개념으로만 사용) 

- Elasticsearch Service 
	. 관리형 서비스 - 간편한 설치, 운용, 확장 
	. 로그분석, 실시간 app 모니터링, 클릭 스트림 분석 
	. Logstash / Kibana 지원 
	
- 데이터 스토어 고려사항 
	. 데이터의 구조? 고정 스키마, json, key-value 
		> 고정스키마 (SQL, NOSQL), 스키마 없는 방식(JSON=NOSQL), 키-밸류(캐쉬, NOSQL), 그래프(graphDB) 
	. 액세스 패턴? 액세스 용이하게 저장 
		> 키-밸류(캐쉬, NOSQL), 단순 관계 1:N, M:N (NOSQL), 크로스 테이블 조인-트랜잭션(SQL), 패시팅-검색(검색),그래프(그래프)
	. 데이터/액세스 특성? 핫, 웜, 콜드
	. 비용? 효율적인가? 
-----------------------------
4. 빅데이터 처리 및 분석 

1) 개요 
	- 빅데이터 처리/분석 워크로드 유형 
		. 배치 : 대량의 콜드 데이터 쿼리, 분~시간, 반구조화 데이터에 대해 한번/두번 처리 - EMR MapReduce
		. 대화형 분석 : 같은 구조화 데이터에서 반복해서 쿼리, 인덱스 및 차원 뷰 같은 사전 계산을 통해 쿼리 성능 향상 - Redshift 
		. 메세지 
		. 스트림 쿼리 : 핫 데이터 , 반구조화, 상대적으로 간단한 계산, 
		. 기계학습 
		
2) Athena 
	- S3 데이터에 대해서 별도의 적재, 변환 작업 없이 SQL 쿼리를 실행 
	- 리전 간에 쿼리를 지원한다 
	- ANSI SQL 연산자 및 함수 지원 
	- 생성, 관리, 확장을 위한 인프라 구축/운영 불필요 -----> 서버리스 아키텍처 ----> 쿼리 단위로 비용 지불 
	- 카탈로그가 glue로 통합 됨 --- 자동 스키마 및 파티션 인식, 구축이 쉬운 파이프라인 
	- SQL 쿼리를 위한 Presto --> 다양한 소스(hdfs, s3)에서 발생하는 데이터 처리가능  
	- DDL 구문은 Hive로 작성되어 수행 
	- 로그분석, QuickSight 데이터 탐색, S3 데이터 레이크 검색 
	- 테이블에서 임의의 열을 기준으로 파티션으로 분할(S3 파티션과 별도?)
	- CSV, TSV, JSON, Apache web, 사용자 지정 텍스트, Parquet, ORC 제공 ---->Parquet, ORC는 성능 향상된다
	- S3에 존재하던 일반 파일들을 열 기반 형식으로 변환하기 위해서는 EMR의 Hive를 쓴다. 
	- 데이터 형식, 인프라 고려 없이 S3에 직접 대화형 쿼리 수행 
		vs EMR : 광범위한 스케일 아웃 데이터 처리 작업 수행. 사용자 지정 코드를 사용해 데이터셋을 처리/분석하는 경우 EMR 사용 
	- 정리 
		> 대화형 '임시' 쿼리 ---> 쿼리에 대해서 과금 
		> 규모, 처리량에 제한 없음 
		> AWS 관리형 서비스 ---> 서버 관리 필요 없음 
		> 스토리지 S3 사용 ---> 데이터 중복 없음, 시간 및 비용 절감 
		> UDF 미지원

<5. 하둡 및 EMR> 
3) EMR 
	- 하둡의 이점 
		. 불확실성 처리 : 다양한 대용량 데이터 처리를 신속하게 분석 
		. 데이터 다양성 처리 : 모든 데이터 파일에 대한 데이터 처리 및 변환 
		. 유연성 제공 : 다양한 유형의 데이터를 처리/ 분석하기 위한 에코 프로젝트 존재 
		. 데이터 볼륨/속도처리 : 필요에 따라서 노드를 
		<> 작은 데이터를 대규모로 처리하는 앱 
	- 하둡 단점 
		. 작은 데이터, 실시간 데이터 처리 안됨 
	- 맵리듀스란?
		. 맵 - 셔플 - 정렬 - 파일출력 
	- HDFS 
		. 파일 분할 기능 
			> 분할 가능한 파일은 데이터를 블록단위로 나누어 mapper를 병렬로 읽음 
			> gzip 같이 분할이 안되는 경우 파일 크기를 2GB 미만으로 유지 
		. 파일 압축 -> 스토리지, 대역폭 비용, 엔진 사이, IO 에 대한 성능 증가 
			> Snappy : 빠른 압축 속도와 높은 효율 (분할 불가) --- 속도에 최적화 
			> gzip : 하둡 기본 압축 프로그램, 높은 압축 효율, 느린 압축속도 
			> bzip2 : 압축 속도가 빠르고, 압축 해제 속도는 더 빠름 
			> LZON : 압축 효율은 gzip 보다 낮음. 
			> 부트스트랩 작업으로 모든 작업을 자동 압축 
			> S3DistCP 는 S3와 HDFS 간 출력을 자동으로 압축 
		. mapreduce.map.output.compress = true 로 하면 셔플 단계에서 데이터 압축(gzip2) 
		
	- Hive 
		. 데이터 파티셔닝 
			> 데이터 형식 (시계열) 
			> 데이터 처리 주기 (단위 별) 
			> 데이터 액세스/쿼리 패턴(시간 vs 지리적 vs 조직별 등) 
		. DDL 로 DynamoDB에 테이블 생성 가능 ??? - DynamoDB의 경로를 external ㅌ이블로 생성 
			
	- EMR	
		. 완리형 클러스터 (몇분 만에 서비스 시작) 
		. 다수의 클러스터 배포, 실행중인 클러스터 크기 조정     ---> 탄력적, 모든 규모 데이터 처리 가능. 동적으로 변경  
		. 기본으로 Hive, Pig, Spark, Hue를 설치 / 옵션으로 Presto, Oozie 설치 
		. AWS CLI , EMR API를 통해 프로그래밍 방식으로 환경 용량 확장/축소 가능 
		. 인프라 관리가 필요없다. ---> 리소스 데이터 분석/처리에 더욱 집중 가능 
		. 실제 사용 리소스에 대해서 요금 청구 , EC2 스팟 인스턴스 및 예약 인스턴스를 기본으로 지원하여 인스턴스 비용 50~80% 절감 
		. 격리된 네트워크 (Amazon VPC)에서 클러스터가 시작됨. 보안그룹으로 인스턴스 액세스 제어 
		. S3 서버 사이드 암호화, 클라이언드 사이드 암호화 지원 
		. AWS KMS , 고객 관리키? 제공 
		. 노드 이슈 발생 시 자동으로 교체가 이루어짐 . 환경 튜닝 및 디버깅이 간편 
		. 여러 데이터 스토어 사용 가능 
		. 초기 구축 시의 비용(설꼐 및 인프라 구성)이 줄어드는 것이 가장 큰 장점 
		
	- 아키텍처 
		. Master #1 > 클러스터 제어, RM, NN 수행. 코어 및 작업 노드 상태 모니터링 
		. Core Instance #1이상 > DN, NM 수행 
		. 클러스터 크기 따라서 기본 복제본 수가 달라짐 
			> 1~3 (1개), 4~9(2개), 10+(3개) 
		. 작업 인스턴스 > 선택사항으로 스토리지를 인스턴스 그룹에 포함시키지 않고 NM 데몬 만을 포함함 
		
<6. EMR 사용> 
