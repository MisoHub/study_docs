<목차> 

1. 빅데이터 수집 및 전송 
2. 빅데이터 스트리밍 및 Kinesis 
3. 빅데이터 스토리지 솔루션 
4. 빅데이터 처리 및 분석 (Athena) 
5. Hadoop 및 EMR 
6. EMR 사용 
7. EMR에서 Hive로 서버 로그 처리하기 
8. EMR 의 Hue에서 Pig 스크립트 실행하기 
9. EMR 기반 Spark 
10. Glue를 사용한 ETL 자동화 
11. Redshift 및 빅데이터 
12. 배포 보안 
13. 빅데이터 비용 관리 
14. 빅데이터 시각화 및 조정 
15. 빅데이터 설계 패턴 
---------------------------------------------------------------
<분류> 
수집 
	- 준실시간 > Kinsis Firehose 
	- 데이터 적재 > Snowball 
	- 메세지 대기열 > SQS 
	- 웹/앱서버 > EC2 
	
저장 
	- 객체 스토리지 : S3, Glacier 
	- 준실시간 : Kinesis Stremas 
	- RDBMS : RDS 
	- NoSQL : DynomoDB 
	- 검색 : CloudSearch 
	- 사물인터넷 : IoT 

처리 및 분석 
	- 하둡에코 : EMR 
	- 준실시간 : Lambda, Kinesis Analytics 
	- DW : Redshift 
	- ML기계학습 : SageMaker 
	- 탄력적 검색 분석 : Elasticsearch Service 
	- 데이터 처리 및 이전 : Data Pipeline , Glue 
	- 임시분석 Athena 
	
시각화 
	- BI 및 시각화 : QuickSight 
	- 탄력적 검색 분석 : Elasticsearch Service 

---------------------------------------------------------------
<0. 빅데이터 아키텍처 원칙>
1) 결합 해제 
	- 저장 -> 처리 -> 저장 -> 처리 ... (결합을 해제)
	- 내결함성이 향상된다. 중간 작업이 실패하는 경우 중간 단계부터 수행할 수 있다. 
	- 복수의 처리 어플리케이션이 복수의 데이터 스토어에서 데이터를 읽고 슬 수 있다. (병렬 처리 가능) 
	- 중간 단계의 데이터를 사용자가 볼 수 있음으로 쉽게 통찰을 얻을 수 있다. 
	
2) 올바른 도구 사용 
	- 데이터 구조 : 처리 방법과 저장소 모두에 영향
	- 최대 허용 지연 시간 
	- 최소 허용 처리량 : 처리량과 지연시간은 일반적으로 상반된 속성으로 어디에 가중치를 둘 것이냐가 중요
	- 시스템 최종 사용자의 일반적인 액세스 패턴 : 배치? 실시간? / 전체 데이터? 일부 데이터? 
	
3) 가능한 경우 관리형 서비스 활용 
	- Kinesis, Redshift, RDS, DynamoDB, Lambda, Elasticsearch Service, Cloudsearch, SQS, Data Pipeline, Beanstalk, SageMaker
	
---------------------------------------------------------------
<1. 빅데이터 수집 및 전송>
1) 수집 유형 
	- 트랜잭션 (DB read/write) 
		. 웹/앱서버 에서 발생하는 작은 크기의 데이터를 신속하게 저장하고 검색할 수 있어야 한다.  
		. DynamoDB, RDS 
	- 파일 
		. 디바이스 등에서 생성되는 개별파일 데이터는 빠른 저장 및 검색이 필요하지 않고, 전송이 일방향 이고, 다양한 소스로부터 수집이 이루어진다. 
		. Flume, Log4j 등을 통해서 S3에 적재 
	- 스트림
		. 클릭스트림 로그와 같은 스트림 데이터는 Fluentd, Sqoop, Storm, Kinesis producer, Kinesis Firehose를 통해 수집 
		. Kinesis Streams와 같은 스트림 스토리지 솔루션에 저장 수 실시간 처리 및 분석 
		. 장기간으로는 S3에 저장해야 됨 

2) 수집 도구 
	. Kinesis Agent 
		> Kinesis Data Streams, Kinesis Data Firehose에 직접 쓸 수 있다. 
		> Linux 기반 서버 환경에 설치하여 수집 파일을 지속적으로 모니터링 하고 전처리하여 신규 데이터를 Kinesis Streams/Firehose에 전송한다. 
		> CloudWatch에 지표를 생성하여 스트리밍 프로세스 모니터링 및 지표를 알려준다. 
		> SINGLELINE, CSVTOJSON, LOGTOJSON 기능 제공 및 오픈소스 임으로 추가 개발 확장 가능하다. 
	
	. Apache Flume 
		> EC2 인스턴스 등에 설치하여 HDFS 또는 S3에 대용량 로그데이터를 효율적으로 수집/집계할 수 있다. 
		
	. S3DistCP 
		> S3와 HDFS간 대용량 데이터 복사를 가능하게 함 , 또는 S3 버킷 간 데이터 복사 
		> HDFS to S3 일 경우) HDFS 출력 임시본 생성 -> S3에 최종 복사본 업로드 -> HDFS 에서 임시본 제거.  단, 중간에 에러나는 경우 임시본 수동 삭제 필요 
		> S3DistCP 하는 경우 비압축 데이터를 압축하여 전송시킬 수 있다. 
		> 파일이 존재하면 덮어 씀. S3 버킷 이름에 언더바 있는 경우 복사 안됨 
	
	. Sqoop 
		> RDB, HDFS 양방향 전송. 맵 전용 작업 생성. (EMR 사용하는 경우 사용함. DW에 데이터를 쓰고 시각화 도구를 통해 통찰 얻을 수 있음) 
		
	. VPC 구성 및 VPN 연결 
		> 해당 구성을 통해 사내 데이터 센터와 연결하여 AWS 빅데이터 서비스를 사용할 수 있음. 
		> 인터넷 -> VPN -> AWS Virtual GW -> AWS subnet  연결 
	
	. VPC 구성 및 DirectConnect(DX) 연결 
		> 고객 onprem에서 AWS로 전용 네트워크 연결 가능 
		> 전용 망을 사용하기 때문에, 네트워크 비용 줄이고 대역폭을 늘리 수 있으며 일관된 네트워크 환경 제공 
		> 퍼블릭/프라이빗 유지하면서 프라이빗 리소스에도 접근이 가능함 
		
	. S3 멀티파트 업로드 
		> S3는 단일 업로드 최대 5GB 크기 객체 업로드, 5MB ~5TB 까지 멀티 파트 업로드 가능, 100 MB 이상의 객체는 멀티파트 업로드 사용 권장. 
		> 멀티파트 업로드로 Direct Connect, VPN, 또는 인터넷 연결을 통해 파일 전송 가능 . 
	
	. Snowball 
		> 페타 바이트 규모의 데이터 전송 솔루션. 보안 어플라이언스를 사용해 대량 데이터 전송.
		> 클라우드 마이그레이션, 재해복구 -> AWS Snowball 
		> 사물인터넷, 원격 위치 -> AWS Snowball Edge  , 자체적으로 로컬 클러스터링 구성. 원격지에서 전송 (스토리지를 컴퓨팅 기능과 함께 로컬 환경에 구현). Lambda 함수 실행. 네트워크 연결 가능. 
		> 엑사 바이트 규모 데이터 센터 이전 -> Snowmobile (초당 1TB, 10PB 이상은 추천) 
		
	. AWS IoT
		> 디바이스가 클라우드 앱 및 다른 디바이스와 상호작용할 수 있도록 함 
		> 인프라 관리 필요 없이 수십억 개 디바이스와 수조 건의 메세지 지원. 데이터 수집 저장 및 분석 처리 
		> Lambda, Kinesis, S2, ML, DynamoDB 와 통합 가능 
		> 규칙엔진으로 데이터를 자동으로 필토링 하고 변환. (json 형태로 정의) 
		
---------------------------------------------------------------
<2. 빅데이터 스트리밍 처리 및 Kinesis>
1) 스트리밍 데이터 솔루션 사용 이유 
	- 수집과 처리의 분리 
	- 복수의 스트림 동시 처리 
	- 클라이언트 순서 유지 
	- 병렬 소비 

2) 스트림 처리 솔루션 특징 
	- 짧은 지연 시간 
	- 메세지 전송 보장 
	- lambda 아키텍처 구현 
	- 스트림 데이터의 상태 관리 
	- 시간 또는 횟수 기반 범위 지정 지원 
	- 내결함성 

3) Kinesis
	- Data Firehose (스트림 캡처 -> 변환 -> 적재) , 지연 60초
		. 완전 관리형 서비스로 스트리밍 데이터를 lambda 를 통해 변환하여 Data Analytics, S3, Redshift, ES 로 적재하여 준실시간 분석 처리 가능하게 함. 
		. 데이터를 로드 하기 전에 배치 처리, 압축 및 암호화 가능 (배치?) 
		. 스트림 생성(리스너) ->Kinesis Agent  또는 Firehose API(PutRecord, PutRecordBatch) 에서 스트림에 데이터 전달 -> 설정한 Lambda를 통해 변환 -> 타겟 적재 (S3, Redshift)
		. 처리된 데이터 양에 대해서 과금 
		. 전송스트림Delivery Stream - Firehose 기반 엔티티로 delivery stream 생성후 데이터를 delivery stream으로  전달
		. 레코드는 blob 단위로 데이터 생산자(kinesis agent / firehose API)에서 delivery stream 으로 전송. 최대 크기 1MB 
		. 타겟에 적재 전에 일정 단위로 버퍼링 후 전달한다. 버퍼링 크기 단위 MB, 시간 단위 초 
		. 파티션 키 없음, 프로비저닝 없음, 샤딩 없음 -(알아서 다 해줌?)
		
	- Data Streams , 생성자-스트림-소비자, 지연 10초 
		. 관리형 서비스로 실시간 스트리밍 데이터 수집, 처리, 및 분석 수행 
		. Data Streams 스트림 생성(샤드 설정) -> Kinesis 생산자가 스트림에 데이터 넣어줌 -> Kinesis 소비자가 
		. 여러 소비자가 동시에 하나의 스트림으로 부터 데이터를 읽을 수 있음. 다양한 타겟에 데이터 전달 가능 
		. 소비자=kinesis app 에서는 데이터 처리, 분석, 학습이 수행될 수 있으며 처리 후 타겟에 적재 가능하다. 
		. 샤드 당 초당 5건/2MB의 읽기 지원. 초당 1000건 쓰기/1MB의 쓰기 지원. 
		. 소비자(kinesis app)은 EC2인스턴스에 올릴 수 있고 ASG를 통해 확장할 수 있다. 
	
	- Kinesis Client Library (KCL) : Kinesis Data Stream을 처리하기 위한 라이브러리. 샤드를 간단하게 해줘 읽고 처리하기 편하게 해준다. 샤드 수에 따라 worker 를 늘리고 줄인다. check pint 추적, 내결함성 
	- Kinesis Connector Library : kinesis 를 다양한 타겟에 붙여준다. 
	
	- Kinesis Firehose와 Kinesis Streams 비교 
		. KF(완전 관리형-관리 필요 없음) vs KS(유입 레코드에 대한 사용자 지정 처리 필요) 
		. KF(처리 지연 시간 60초) vs KS(처리 지연시간 1초) 
		. KF(S3, Redshift, ES 등 기존 분석 도구 사용) vs KS(스트림 처리 프레임워크 선택?-소비자 app 개발, storm/spark) 
	
	- Data Analytics 
		. 완전 관리형 서비스 
		. 원본 데이터 Kinesis Streams / Kinesis Firehose 의 스트림 
		. KS, KF의 스트림 연결 후 Kinesis Data analytics 로 SQL수행 
		. 자동으로 스키마 추론함 
		. 1초 미만의 처리 지연 시간 
		. S3를 참조 데이터 원본으로 app 시작시 참조 테이블 생성 
		. 처리된 데이터를 S3, RS, ES, 또 다른 스트림 으로 전달(lambda를 통해 사용) 

	- Video Streams : 생산자/소비자 구조. VS가 내부적으로 처리/변환 수행 
	- Spark Streaming : 1초 미만의 마이크로 배치 (RDD의 시퀀스인 Dstreams사용) 
	- Kafka  : MS, Kafka stream 을 통해 데이터 처리 및 분석 수행 . 
	- on EC2  : Flume, Storm, Samza, Flink 
	
	- 처리 예시1) 
	> 클릭 스트림 로그는 별도 처리가 필요 없음으로 Firehose 스트림으로 수집 후 S3에 적재. 장기 데이터는 Glacier로 이동. 
	> 복잡한 처리가 필요한 스트림 데이터는 Kinesis streams 에 적재(생산자가 선택적으로 특정 스트림에 적재 할 수 있음), 후 적재된 스트림 따라서 소비자 app이 처리하여 결과를 S3에 저장 
	
	- 처리 예시2) 
	> 원본 데이터는 S3에 별도 적재 , 동시에 해당 스트림을 소비자 앱에 보낼 수 있음 (fork 같이) 
	> 처리 실패 건에 대해서도 별도 저장을 수행해야 함 
	
	- 추가 스트리밍 저장 옵션 
		. DynamoDB Streams 
		. SQS
		. SNS (pub/sub) 
		
	- !!! 어떤 스트림 스토리지를 사용해야 하는가? 
		. 관리형 우선 - Kinesis 같은 관리형 서비스는 관리 포인트가 줄어든다.  + 서버리스 
		. 순서 지정 - Stream 순서 지정은 순서대로 데이터를 소비할 수 있게 해준다. Kinesis (data streams) 는 샤드 수준에서만 순서를 보장한다!!!
		. Kinesis 는 최소 한번 전송만 보장함으로, 두번이상 데이터를 보내는 경우가 발생할 수 있다. 따라서 이후 중복 제거 작업을 통해 대처해야 한다. 
		. KS 는 데이터 유지기간 7일, KF는 별도 데이터 유지기간 없음 (바로 전달하기 때문에) 

	##### 스트림 프로세서 선택 기준 
		. 어느정도의 처리량? 
		. 확장 / 축소 기능을 가지고 있나? 
		. 내결함성을 가지고 있나? 
		. 전송 보장을 제공하나?
		. 어떤 프로그래밍 언어를 지원하나? 
		. 누가 관리할 것인가? (뭐가 관리형 서비스냐?) 
		
---------------------------------------------------------------

